# Django Chat com IA (FAQ)

## ğŸ“‹ Sobre o Projeto

Este Ã© um projeto de **chat interativo** desenvolvido em Django que utiliza **inteligÃªncia artificial** para responder Ã s perguntas frequentes (FAQ) dos usuÃ¡rios. Quando o usuÃ¡rio nÃ£o encontra a resposta correta ou estÃ¡ com dÃºvidas, o sistema utiliza um modelo de IA baseado no **Llama 3.1** para fornecer suporte adicional e orientar o usuÃ¡rio na navegaÃ§Ã£o pelos menus.

AlÃ©m disso, o sistema mantÃ©m um **histÃ³rico de conversas** baseado na sessÃ£o do Django, permitindo que o usuÃ¡rio acompanhe o contexto e as respostas durante a interaÃ§Ã£o.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Django**: Framework web backend para gerenciar rotas, lÃ³gica do chat, API e sessÃµes.
- **LangChain**: Para gerenciamento do fluxo de conversaÃ§Ã£o e integraÃ§Ã£o com o modelo de IA.
- **Ollama**: Biblioteca para acessar e executar o modelo Llama 3 localmente.
- **Python-Decouple**: Para gerenciar configuraÃ§Ãµes sensÃ­veis, carregando variÃ¡veis de um arquivo `.env` de forma segura e organizada.

---

## ğŸ“¦ Funcionalidades

- **Respostas automÃ¡ticas** para perguntas frequentes (FAQ).
- **Suporte via IA** para perguntas nÃ£o respondidas diretamente.
- **HistÃ³rico de conversas** baseado na sessÃ£o do Django.

---

## ğŸ¤– Exemplos de Perguntas Suportadas

1. **Perguntas Frequentes:**

- "Qual o horÃ¡rio de atendimento?"
- "Quais os meios de pagamento disponÃ­veis?"

2. **Respostas via IA:**

- Quando o usuÃ¡rio digita algo como: "NÃ£o sei como resolver meu problema", o modelo Llama 3 fornece orientaÃ§Ãµes ou sugere um item do menu.

2. **HistÃ³rico de Conversas:**

- O histÃ³rico Ã© salvo e exibido durante a sessÃ£o ativa, permitindo que o usuÃ¡rio veja perguntas e respostas anteriores.

---

## ğŸ“‚ Estrutura do Projeto

    .
    â”œâ”€â”€ chatbot/               # App do chat
    â”‚   â”œâ”€â”€ models.py          # Modelos de dados
    â”‚   â”œâ”€â”€ views.py           # LÃ³gica das views do chat
    â”‚   â”œâ”€â”€ urls.py            # Rotas do app Chatbot
    â”‚   â”œâ”€â”€ templates/         # Templates HTML
    |   â”œâ”€â”€ ai_model           # LÃ³gica do modelo de IA
    â”‚   â””â”€â”€ utils.py           # FunÃ§Ãµes auxiliares (ex.: manipulaÃ§Ã£o do )
    â”œâ”€â”€ core/                  # App principal do Django
    â”‚   â”œâ”€â”€ models.py          # Modelos de dados
    â”‚   â”œâ”€â”€ views.py           # LÃ³gica das views principal
    â”‚   â”œâ”€â”€ urls.py            # Rotas do app
    â”‚   â”œâ”€â”€ templates/         # Templates HTML
    â”œâ”€â”€ project/               # ConfiguraÃ§Ãµes do projeto Django
    â”‚   â”œâ”€â”€ settings.py        # ConfiguraÃ§Ãµes principais
    â”‚   â””â”€â”€ urls.py            # Rotas root
    â”œâ”€â”€ requirements.txt       # DependÃªncias do projeto
    â”œâ”€â”€ .env                   # ConfiguraÃ§Ã£o de Ambiente
    â””â”€â”€ README.md              # DocumentaÃ§Ã£o do projeto

---

## âš™ï¸ ConfiguraÃ§Ã£o de Ambiente

1. **Crie um arquivo .env na raiz do projeto**

    ```bash
    touch .env #Linux
    mkdir .env #Windows
    ```

2.  **Certifique-se de definir as variÃ¡veis de ambiente necessÃ¡rias no arquivo .env:**
    
    ```bash
    DJANGO_SECRET_KEY='chaveaqui'
    ```

---

## ğŸš€ Como Rodar o Projeto

### PrÃ©-requisitos

1. **Python 3.12.7**
2. **Django 5.1.3** (instalado no ambiente virtual)
3. **Ollama 0.4.2** (para executar o modelo Llama 3)
4. **LangChain 0.3.19** (para gerenciar fluxos de conversaÃ§Ã£o)

### Passo a Passo

1. **Clone este repositÃ³rio**

   ```bash
   git clone https://github.com/Kenjix/chat-bot.git
   cd seu-repositorio
   ```

2. **Crie e ative o ambiente virtual**

    ```bash
    python -m venv venv
    source venv/bin/activate  # No Windows: venv\Scripts\activate
    ```

3. **Instale as dependÃªncias**

    ```bash
    pip install -r requirements.txt
    ```

4. **Configure o Ollama**

- Instale o Ollama CLI conforme documentaÃ§Ã£o oficial.
- Baixe o modelo llama3.1:8b:

    ```bash
    ollama pull llama3.1:8b
    ```

5. **Realize as migraÃ§Ãµes do Django**

    ```bash
    python manage.py migrate
    ```

6. **Inicie o servidor**

    ```bash
    python manage.py runserver
    ```

7. **Acesse a aplicaÃ§Ã£o**

- Abra seu navegador e acesse: http://127.0.0.1:8000.